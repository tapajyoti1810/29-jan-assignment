{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbb1a6-2231-41cb-8395-c0794cdb423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question No. 1:\n",
    "What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach? Explain with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc148c4b-aba5-4a72-8172-c5e0a9d8170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eigenvalues and eigenvectors are mathematical concepts that are used in linear algebra. In simple terms, an eigenvector is a vector that remains in the same direction after a linear transformation, while an eigenvalue is a scalar that scales the eigenvector during this transformation.\n",
    "\n",
    "Eigen-Decomposition is a method used to factorize a matrix into a set of eigenvectors and eigenvalues. It is an important technique in linear algebra and is used in a variety of applications, such as image processing, quantum mechanics, and finance.\n",
    "\n",
    "Example:\n",
    "\n",
    "A = [[2, 1],\n",
    "\n",
    " [1, 2]]\n",
    "\n",
    "A * v = λ * v\n",
    "\n",
    "Substituting the values of A:\n",
    "\n",
    "[[2, 1],\n",
    "\n",
    "[1, 2]] * [x, y] = λ * [x, y]\n",
    "\n",
    "Expanding the equation:\n",
    "\n",
    "2x + y = λx\n",
    "\n",
    "x + 2y = λy\n",
    "\n",
    "Solving for λ:\n",
    "\n",
    "(2 - λ)(2 - λ) - 1 = 0\n",
    "\n",
    "λ^2 - 4λ + 3 = 0\n",
    "λ1 = 1\n",
    "λ2 = 3\n",
    "\n",
    "Substituting these eigenvalues back into the original equation, we can solve for the eigenvectors:\n",
    "For λ1 = 1:\n",
    "\n",
    "2x + y = x\n",
    "\n",
    "x + 2y = y\n",
    "\n",
    "Solving for x and y, we get:\n",
    "\n",
    "x = -y\n",
    "\n",
    "Thus, the eigenvector corresponding to λ1 = 1 is:\n",
    "\n",
    "v1 = [-1, 1]\n",
    "\n",
    "Similarly, for λ2 = 3:\n",
    "\n",
    "2x + y = 3x\n",
    "\n",
    "x + 2y = 3y\n",
    "\n",
    "Solving for x and y, we get:\n",
    "\n",
    "x = y\n",
    "\n",
    "Thus, the eigenvector corresponding to λ2 = 3 is:\n",
    "\n",
    "v2 = [1, 1]\n",
    "\n",
    "Now that we have found the eigenvectors and eigenvalues of A, we can write the matrix A as a product of these eigenvectors and eigenvalues:\n",
    "\n",
    "A = PDP^-1\n",
    "\n",
    "where P is a matrix containing the eigenvectors and D is a diagonal matrix containing the eigenvalues. In our example, we have:\n",
    "\n",
    "P = [[-1, 1],\n",
    "\n",
    " [1, 1]]\n",
    "\n",
    "D = [[1, 0],\n",
    "\n",
    " [0, 3]]\n",
    "\n",
    "Thus, the eigen-decomposition of A is:\n",
    "\n",
    "A = [[2, 1],\n",
    "\n",
    " [1, 2]] = [[-1, 1],<br>\n",
    "            [1, 1]] * [[1, 0],<br>\n",
    "                       [0, 3]] * [[-1, 1],<br>\n",
    "                                  [1, 1]]^-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d2ad0-7f50-4b20-8b4f-ef7ae93d9740",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question No. 2:\n",
    "What is eigen decomposition and what is its significance in linear algebra?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f46b1-d3f8-4c21-ae0b-0a49d0dead32",
   "metadata": {},
   "source": [
    "Answer:\n",
    "Eigen decomposition, also known as eigendecomposition or spectral decomposition, is a process of diagonalizing a matrix into a set of eigenvectors and corresponding eigenvalues. In other words, it is a way to factorize a matrix into simpler components that can be more easily analyzed and manipulated.\n",
    "\n",
    "In linear algebra, eigen decomposition has a significant role and is used in many applications. Some of its important applications are:\n",
    "\n",
    "Finding the principal components of a data set: Eigen decomposition is commonly used in data analysis to find the principal components of a data set. The eigenvectors of the covariance matrix of the data set are the principal components, and the corresponding eigenvalues represent the amount of variance explained by each principal component.\n",
    "\n",
    "Solving differential equations: Eigen decomposition can be used to solve differential equations of the form y' = Ay, where A is a constant matrix and y is a vector function. The solution can be expressed in terms of the eigenvectors and eigenvalues of A.\n",
    "\n",
    "Image processing: Eigen decomposition can be used in image processing for image compression, feature extraction, and noise reduction.\n",
    "\n",
    "Quantum mechanics: Eigen decomposition plays a fundamental role in quantum mechanics, where it is used to find the energy levels and wave functions of quantum systems.\n",
    "\n",
    "Network analysis: Eigen decomposition is used in network analysis to find the centrality of nodes in a network. The eigenvector centrality of a node is proportional to the sum of the centrality of its neighboring nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8cff8-9f8c-4cd4-ab1e-ad9b5e6e6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question No. 3:\n",
    "What are the conditions that must be satisfied for a square matrix to be diagonalizable using the Eigen-Decomposition approach? Provide a brief proof to support your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485c403-025e-4253-968f-4dca21e750ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer:\n",
    "A square matrix is diagonalizable if and only if it has a set of linearly independent eigenvectors. The condition for diagonalizability can be stated as follows: a square matrix A is diagonalizable if and only if it has n linearly independent eigenvectors, where n is the size of the matrix.\n",
    "\n",
    "Proof:\n",
    "\n",
    "First, let's assume that A is diagonalizable, which means that it can be written as A = PDP^(-1), where D is a diagonal matrix containing the eigenvalues of A, and P is a matrix containing the eigenvectors of A. Since A is diagonalizable, it follows that:\n",
    "\n",
    "AP = PD\n",
    "\n",
    "Multiplying both sides of the equation by P^(-1), we get:\n",
    "\n",
    "A = PDP^(-1)\n",
    "\n",
    "So, we can write:\n",
    "\n",
    "AP = PDP^(-1)P = PD\n",
    "\n",
    "which implies that:\n",
    "\n",
    "AP = PD\n",
    "\n",
    "This equation shows that the columns of P are eigenvectors of A, and the diagonal entries of D are the corresponding eigenvalues. Therefore, A has n linearly independent eigenvectors.\n",
    "\n",
    "Conversely, suppose that A has n linearly independent eigenvectors. Let P be the matrix whose columns are these eigenvectors, and let D be the diagonal matrix containing the corresponding eigenvalues. Then, we can write:\n",
    "\n",
    "AP = PD\n",
    "\n",
    "Multiplying both sides by P^(-1), we get:\n",
    "\n",
    "A = PDP^(-1)\n",
    "\n",
    "This shows that A is diagonalizable. Therefore, if a square matrix A has n linearly independent eigenvectors, it is diagonalizable using the Eigen-Decomposition approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d5186-88dc-4454-9297-5158736d0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question No. 4:\n",
    "What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach? How is it related to the diagonalizability of a matrix? Explain with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ce5d2-a349-4fc7-a01b-eeed308b25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer:\n",
    "The spectral theorem is a fundamental result in linear algebra that connects the Eigen-Decomposition approach to the diagonalizability of\n",
    "a matrix. The theorem states that a symmetric matrix is always diagonalizable, which means that it can be factorized into a set of eigenvector\n",
    "s and corresponding eigenvalues. Moreover, the eigenvalues are real and the eigenvectors can be chosen to be orthogonal.\n",
    "\n",
    "This theorem is significant in the context of the Eigen-Decomposition approach because it provides a powerful tool for analyzing and\n",
    "\n",
    "manipulating symmetric matrices. In particular, it allows us to find the eigenvalues and eigenvectors of a symmetric matrix, which can be used\n",
    "for various applications such as data analysis, image processing, and quantum mechanics.\n",
    "\n",
    "For example, consider the following symmetric matrix:\n",
    "\n",
    "A = [ 4 2 2 5 ]\n",
    "\n",
    "To find the eigenvalues and eigenvectors of A, we first compute the characteristic polynomial:\n",
    "\n",
    "det(A - λI) = 0\n",
    "\n",
    "where λ is the eigenvalue and I is the identity matrix. Solving for λ, we get:\n",
    "\n",
    "λ^2 - 9λ + 14 = 0\n",
    "\n",
    "which has roots λ = 2 and λ = 7. These are the eigenvalues of A.\n",
    "\n",
    "To find the eigenvectors corresponding to these eigenvalues, we solve the equations (A - λI)x = 0 for each eigenvalue. For λ = 2, we get:\n",
    "\n",
    "[ 2 -2 [x1\n",
    "-2 3 ] x2 ] = 0\n",
    "\n",
    "Solving this system, we find that the eigenvectors corresponding to λ = 2 are:\n",
    "\n",
    "v1 = [1, -1] and v2 = [-1, 1]\n",
    "\n",
    "For λ = 7, we get:\n",
    "\n",
    "[ -3 -2 [x1\n",
    "-2 -2 ] x2 ] = 0\n",
    "\n",
    "Solving this system, we find that the eigenvectors corresponding to λ = 7 are:\n",
    "\n",
    "v3 = [2, -1] and v4 = [1, -2]\n",
    "\n",
    "These eigenvectors are orthogonal to each other, which means that we can form an orthogonal matrix P from them:\n",
    "\n",
    "P = [ v1 v2 v3 v4 ]\n",
    "\n",
    "Finally, we can form the diagonal matrix D containing the eigenvalues:\n",
    "\n",
    "D = [ 2 0 0 0\n",
    "0 2 0 0\n",
    "0 0 7 0\n",
    "0 0 0 7 ]\n",
    "\n",
    "Then, we can write A as:\n",
    "\n",
    "A = PDP^(-1)\n",
    "\n",
    "This is the Eigen-Decomposition of A, and it shows that A is diagonalizable by the Eigendecomposition approach. The diagonalization of A\n",
    "allows us to easily analyze its properties, such as its eigenspectrum and eigenspace. Moreover, the spectral theorem tells us that the\n",
    "eigenvectors of A can be chosen to be orthogonal, which has many practical applications in areas such as signal processing and machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85417137-e418-456d-b9fc-54b4ad36f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question No. 5:\n",
    "How do you find the eigenvalues of a matrix and what do they represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d75a7-bf96-4a7e-8fad-008b779ce8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer:\n",
    "To find the eigenvalues of a matrix, we need to solve the characteristic equation:\n",
    "\n",
    "det(A - λI) = 0\n",
    "\n",
    "where A is the matrix, λ is the eigenvalue, and I is the identity matrix of the same size as A.\n",
    "\n",
    "The eigenvalues of a matrix represent the values by which the matrix stretches or shrinks the eigenvectors. In other words, if v is an eigenvector of A corresponding to the eigenvalue λ, then Av = λv. This equation tells us that the matrix A scales the vector v by the factor λ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf37b17-32c6-46b2-9e0d-c23927810874",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question No. 6:\n",
    "What are eigenvectors and how are they related to eigenvalues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e0872-5c0c-48a8-98a0-2ef10ae385c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer:\n",
    "Eigenvectors are non-zero vectors that, when multiplied by a matrix, result in a scalar multiple of themselves. More formally, let A be an n×n\n",
    "matrix and let λ be a scalar. A non-zero vector v is said to be an eigenvector of A corresponding to the eigenvalue λ if Av = λv.\n",
    "\n",
    "In other words, the matrix A stretches or shrinks the eigenvector v by a factor of λ. The magnitude of λ represents the scaling factor, and the\n",
    "direction of v remains unchanged. Thus, eigenvectors are important because they describe the directions in which a matrix stretches or shrinks \n",
    "space.\n",
    "\n",
    "Eigenvectors are closely related to eigenvalues because every eigenvalue has at least one corresponding eigenvector. In fact, if a matrix\n",
    "A has n linearly independent eigenvectors, then it can be decomposed into the product of a diagonal matrix D containing the eigenvalues and a \n",
    "matrix P whose columns are the eigenvectors of A. This is known as the Eigen-Decomposition of A, and it has many important applications in\n",
    "linear algebra, such as diagonalization of matrices, solving differential equations, and computing the power of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7a766-329b-40a3-a7fa-8fd7a4786d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d63d5-a918-4181-bb69-738c29ad2fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e2e3e-96b1-43c2-865a-a2bc4b097230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
